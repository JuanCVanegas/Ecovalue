{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('InterpolatedWithCAPEX.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dates</th>\n",
       "      <th>D REVENUE</th>\n",
       "      <th>U CR</th>\n",
       "      <th>D OE</th>\n",
       "      <th>D NOI</th>\n",
       "      <th>D FCF</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2009-12-31</td>\n",
       "      <td>1884.372544</td>\n",
       "      <td>976.202014</td>\n",
       "      <td>475.249997</td>\n",
       "      <td>757.519678</td>\n",
       "      <td>1071.834493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-31</td>\n",
       "      <td>1884.566826</td>\n",
       "      <td>983.762225</td>\n",
       "      <td>485.004015</td>\n",
       "      <td>734.017979</td>\n",
       "      <td>1033.190422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-02-28</td>\n",
       "      <td>1884.761107</td>\n",
       "      <td>991.322435</td>\n",
       "      <td>494.758033</td>\n",
       "      <td>710.516281</td>\n",
       "      <td>994.546350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-03-31</td>\n",
       "      <td>1884.955389</td>\n",
       "      <td>998.882646</td>\n",
       "      <td>504.512051</td>\n",
       "      <td>687.014582</td>\n",
       "      <td>955.902279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-04-30</td>\n",
       "      <td>1880.767673</td>\n",
       "      <td>1006.377690</td>\n",
       "      <td>481.542613</td>\n",
       "      <td>511.922217</td>\n",
       "      <td>928.473553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>2019-11-30</td>\n",
       "      <td>1146.881815</td>\n",
       "      <td>433.816967</td>\n",
       "      <td>436.290714</td>\n",
       "      <td>460.509240</td>\n",
       "      <td>733.164793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>2019-12-31</td>\n",
       "      <td>1111.642375</td>\n",
       "      <td>415.370593</td>\n",
       "      <td>431.490513</td>\n",
       "      <td>417.984787</td>\n",
       "      <td>729.764211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>1142.095113</td>\n",
       "      <td>422.618925</td>\n",
       "      <td>430.139254</td>\n",
       "      <td>424.521959</td>\n",
       "      <td>737.713784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>2020-02-29</td>\n",
       "      <td>1172.547851</td>\n",
       "      <td>429.867258</td>\n",
       "      <td>428.787994</td>\n",
       "      <td>431.059130</td>\n",
       "      <td>745.663358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>2020-03-31</td>\n",
       "      <td>1203.000589</td>\n",
       "      <td>437.115591</td>\n",
       "      <td>427.436735</td>\n",
       "      <td>437.596301</td>\n",
       "      <td>753.612931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>124 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Dates    D REVENUE         U CR        D OE       D NOI        D FCF\n",
       "0    2009-12-31  1884.372544   976.202014  475.249997  757.519678  1071.834493\n",
       "1    2010-01-31  1884.566826   983.762225  485.004015  734.017979  1033.190422\n",
       "2    2010-02-28  1884.761107   991.322435  494.758033  710.516281   994.546350\n",
       "3    2010-03-31  1884.955389   998.882646  504.512051  687.014582   955.902279\n",
       "4    2010-04-30  1880.767673  1006.377690  481.542613  511.922217   928.473553\n",
       "..          ...          ...          ...         ...         ...          ...\n",
       "119  2019-11-30  1146.881815   433.816967  436.290714  460.509240   733.164793\n",
       "120  2019-12-31  1111.642375   415.370593  431.490513  417.984787   729.764211\n",
       "121  2020-01-31  1142.095113   422.618925  430.139254  424.521959   737.713784\n",
       "122  2020-02-29  1172.547851   429.867258  428.787994  431.059130   745.663358\n",
       "123  2020-03-31  1203.000589   437.115591  427.436735  437.596301   753.612931\n",
       "\n",
       "[124 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['2009-12-31', 1884.372544, 976.2020142, 475.24999739999987,\n",
       "        757.519678, 1071.834493],\n",
       "       ['2010-01-31', 1884.5668256666668, 983.7622247333335, 485.0040154,\n",
       "        734.0179793333333, 1033.1904216666667],\n",
       "       ['2010-02-28', 1884.761107333333, 991.3224352666666,\n",
       "        494.75803339999993, 710.5162806666667, 994.5463503333333],\n",
       "       ['2010-03-31', 1884.955389, 998.8826458, 504.5120514, 687.014582,\n",
       "        955.902279],\n",
       "       ['2010-04-30', 1880.767673333333, 1006.3776901999997,\n",
       "        481.5426128333333, 511.92221730000006, 928.4735526333333],\n",
       "       ['2010-05-31', 1876.5799576666668, 1013.8727346000001,\n",
       "        458.5731742666666, 336.8298526000001, 901.0448262666665],\n",
       "       ['2010-06-30', 1872.392242, 1021.367779, 435.6037357, 161.7374879,\n",
       "        873.6160999],\n",
       "       ['2010-07-31', 1853.240114, 1015.1698886666666, 421.8261523,\n",
       "        187.6358415, 863.0179451333332],\n",
       "       ['2010-08-31', 1834.087986, 1008.9719983333333, 408.0485689,\n",
       "        213.5341951, 852.4197903666667],\n",
       "       ['2010-09-30', 1814.935858, 1002.774108, 394.2709855, 239.4325487,\n",
       "        841.8216356],\n",
       "       ['2010-10-31', 1851.320774, 1008.5464486666666, 411.1460836666666,\n",
       "        246.73378476666667, 855.6692487],\n",
       "       ['2010-11-30', 1887.70569, 1014.3187893333335, 428.0211818333333,\n",
       "        254.03502083333333, 869.5168617999999],\n",
       "       ['2010-12-31', 1924.090606, 1020.09113, 444.89628, 261.3362569,\n",
       "        883.3644749],\n",
       "       ['2011-01-31', 1840.631611, 1004.3123142000001, 439.1857453333333,\n",
       "        253.3520595, 874.4433030666668],\n",
       "       ['2011-02-28', 1757.172616, 988.5334983999999, 433.47521066666667,\n",
       "        245.36786209999997, 865.5221312333334],\n",
       "       ['2011-03-31', 1673.713621, 972.7546826, 427.764676, 237.3836647,\n",
       "        856.6009594000002],\n",
       "       ['2011-04-30', 1697.5040236666666, 943.8024453, 430.2420961,\n",
       "        237.04147333333333, 810.8597272333334],\n",
       "       ['2011-05-31', 1721.2944263333334, 914.850208, 432.71951619999993,\n",
       "        236.69928196666663, 765.1184950666667],\n",
       "       ['2011-06-30', 1745.084829, 885.8979707000002, 435.1969363,\n",
       "        236.3570906, 719.3772629],\n",
       "       ['2011-07-31', 1775.998593, 875.2949231666668, 444.6121419,\n",
       "        236.2388491, 732.4146046],\n",
       "       ['2011-08-31', 1806.912357, 864.6918756333333, 454.02734749999996,\n",
       "        236.1206076, 745.4519462999999],\n",
       "       ['2011-09-30', 1837.826121, 854.0888281, 463.44255310000005,\n",
       "        236.0023661, 758.489288],\n",
       "       ['2011-10-31', 1885.0705423333332, 857.2014145333335,\n",
       "        470.0062231666667, 244.5463731, 756.6899263333332],\n",
       "       ['2011-11-30', 1932.314963666667, 860.3140009666665,\n",
       "        476.56989323333335, 253.0903801, 754.8905646666667],\n",
       "       ['2011-12-31', 1979.559385, 863.4265874, 483.13356330000005,\n",
       "        261.6343871, 753.0912030000002],\n",
       "       ['2012-01-31', 1910.3834399999998, 858.4811889666668,\n",
       "        483.72593293333335, 263.6296255, 715.3372166666667],\n",
       "       ['2012-02-29', 1841.2074949999999, 853.5357905333334,\n",
       "        484.3183025666667, 265.6248639, 677.5832303333334],\n",
       "       ['2012-03-31', 1772.03155, 848.5903921, 484.9106722, 267.6201023,\n",
       "        639.829244],\n",
       "       ['2012-04-30', 1805.3226533333332, 852.7747259666667,\n",
       "        500.10971653333337, 262.53434903333334, 625.4113584666667],\n",
       "       ['2012-05-31', 1838.6137566666666, 856.9590598333334,\n",
       "        515.3087608666667, 257.44859576666664, 610.9934729333334],\n",
       "       ['2012-06-30', 1871.90486, 861.1433937, 530.5078052, 252.3628425,\n",
       "        596.5755874],\n",
       "       ['2012-07-31', 1870.0189613333332, 888.6962120999999,\n",
       "        512.9147551333333, 274.75087963333334, 596.6860897999999],\n",
       "       ['2012-08-31', 1868.1330626666668, 916.2490305,\n",
       "        495.32170506666665, 297.1389167666666, 596.7965922000002],\n",
       "       ['2012-09-30', 1866.247164, 943.8018489, 477.728655, 319.5269539,\n",
       "        596.9070946],\n",
       "       ['2012-10-31', 1872.4550559999998, 871.4747433666665,\n",
       "        485.99178150000006, 323.89898873333334, 628.3878588333333],\n",
       "       ['2012-11-30', 1878.6629480000001, 799.1476378333333, 494.254908,\n",
       "        328.27102356666666, 659.8686230666667],\n",
       "       ['2012-12-31', 1884.87084, 726.8205323, 502.5180345, 332.6430584,\n",
       "        691.3493873],\n",
       "       ['2013-01-31', 1896.30791, 753.0427803333333, 514.5447965666667,\n",
       "        333.5149285333333, 690.0065109333333],\n",
       "       ['2013-02-28', 1907.7449800000002, 779.2650283666666,\n",
       "        526.5715586333333, 334.38679866666666, 688.6636345666667],\n",
       "       ['2013-03-31', 1919.18205, 805.4872763999998, 538.5983207,\n",
       "        335.2586688, 687.3207582],\n",
       "       ['2013-04-30', 1867.7861953333331, 783.4079046999999,\n",
       "        530.8571651000001, 335.86746453333336, 711.6253066666667],\n",
       "       ['2013-05-31', 1816.3903406666666, 761.328533, 523.1160095,\n",
       "        336.47626026666666, 735.9298551333335],\n",
       "       ['2013-06-30', 1764.994486, 739.2491613, 515.3748539, 337.085056,\n",
       "        760.2344036000002],\n",
       "       ['2013-07-31', 1768.6169343333331, 757.7170030999998, 520.4034373,\n",
       "        329.2451542333333, 760.4925157666668],\n",
       "       ['2013-08-31', 1772.2393826666666, 776.1848449, 525.4320207000002,\n",
       "        321.40525246666664, 760.7506279333335],\n",
       "       ['2013-09-30', 1775.861831, 794.6526867, 530.4606041000002,\n",
       "        313.5653506999999, 761.0087401000002],\n",
       "       ['2013-10-31', 1781.312525333333, 813.7964820333333,\n",
       "        531.6057520333334, 320.4643399333333, 761.8369197333334],\n",
       "       ['2013-11-30', 1786.7632196666668, 832.9402773666667,\n",
       "        532.7508999666667, 327.36332916666663, 762.6650993666667],\n",
       "       ['2013-12-31', 1792.2139140000004, 852.0840727, 533.8960479,\n",
       "        334.2623184, 763.493279],\n",
       "       ['2014-01-31', 1772.1792736666669, 861.7296213999998, 528.3798523,\n",
       "        342.6429393, 776.451154],\n",
       "       ['2014-02-28', 1752.144633333333, 871.3751701, 522.8636567,\n",
       "        351.0235602, 789.409029],\n",
       "       ['2014-03-31', 1732.109993, 881.0207187999998, 517.3474611,\n",
       "        359.4041811, 802.366904],\n",
       "       ['2014-04-30', 1721.8949903333335, 890.6855609999999,\n",
       "        507.92859023333335, 349.91219946666666, 793.3964250333332],\n",
       "       ['2014-05-31', 1711.6799876666666, 900.3504032,\n",
       "        498.50971936666673, 340.4202178333333, 784.4259460666666],\n",
       "       ['2014-06-30', 1701.464985, 910.0152454, 489.09084850000005,\n",
       "        330.9282362, 775.4554671],\n",
       "       ['2014-07-31', 1728.4231946666666, 914.2662125, 481.6856930666667,\n",
       "        331.95640223333334, 766.0225778666667],\n",
       "       ['2014-08-31', 1755.3814043333334, 918.5171796,\n",
       "        474.28053763333327, 332.98456826666666, 756.5896886333333],\n",
       "       ['2014-09-30', 1782.339614, 922.7681467, 466.8753822,\n",
       "        334.0127343000001, 747.1567994],\n",
       "       ['2014-10-31', 1725.137324333333, 965.4992654666668,\n",
       "        478.28002593333326, 415.6834258, 757.3171348],\n",
       "       ['2014-11-30', 1667.935034666667, 1008.2303842333333,\n",
       "        489.68466966666665, 497.35411730000004, 767.4774702000001],\n",
       "       ['2014-12-31', 1610.732745, 1050.961503, 501.0893134, 579.0248088,\n",
       "        777.6378056],\n",
       "       ['2015-01-31', 1746.422448666667, 1054.429111, 508.5803035333333,\n",
       "        579.2034107000001, 776.7867944],\n",
       "       ['2015-02-28', 1882.112152333333, 1057.8967189999998,\n",
       "        516.0712936666666, 579.3820125999998, 775.9357832000001],\n",
       "       ['2015-03-31', 2017.801856, 1061.364327, 523.5622838,\n",
       "        579.5606144999998, 775.0847719999998],\n",
       "       ['2015-04-30', 2107.344116, 1096.44801, 526.1169451000002,\n",
       "        577.4851386666667, 774.5279383333333],\n",
       "       ['2015-05-31', 2196.8863760000004, 1131.531693, 528.6716064,\n",
       "        575.4096628333333, 773.9711046666665],\n",
       "       ['2015-06-30', 2286.428636, 1166.615376, 531.2262677, 573.334187,\n",
       "        773.414271],\n",
       "       ['2015-07-31', 2528.4880129999997, 1194.063472, 562.655131,\n",
       "        551.8155191666667, 760.1008118333333],\n",
       "       ['2015-08-31', 2770.5473899999997, 1221.511568, 594.0839943000002,\n",
       "        530.2968513333334, 746.7873526666666],\n",
       "       ['2015-09-30', 3012.606767, 1248.959664, 625.5128576000002,\n",
       "        508.7781835, 733.4738934999998],\n",
       "       ['2015-10-31', 2903.7366663333332, 1269.6701176666666,\n",
       "        641.4096041, 508.9514627, 727.0572944999999],\n",
       "       ['2015-11-30', 2794.8665656666667, 1290.3805713333334,\n",
       "        657.3063506000002, 509.1247419, 720.6406955],\n",
       "       ['2015-12-31', 2685.996465, 1311.091025, 673.2030971, 509.2980211,\n",
       "        714.2240965],\n",
       "       ['2016-01-31', 2834.140780666666, 1366.4444733333332,\n",
       "        674.0792667333334, 500.8613563, 728.1806636666665],\n",
       "       ['2016-02-29', 2982.285096333333, 1421.7979216666665,\n",
       "        674.9554363666666, 492.4246915, 742.1372308333333],\n",
       "       ['2016-03-31', 3130.429412, 1477.1513699999996, 675.831606,\n",
       "        483.9880267, 756.093798],\n",
       "       ['2016-04-30', 3060.8571920000004, 1508.7480799999996,\n",
       "        653.6836567666667, 473.8452801, 771.8714318333333],\n",
       "       ['2016-05-31', 2991.284972, 1540.34479, 631.5357075333333,\n",
       "        463.7025335, 787.6490656666667],\n",
       "       ['2016-06-30', 2921.712752, 1571.9415, 609.3877583, 453.5597869,\n",
       "        803.4266995],\n",
       "       ['2016-07-31', 2979.422658, 1553.679082333333, 612.0762081333334,\n",
       "        473.88566743333337, 790.2704643666667],\n",
       "       ['2016-08-31', 3037.132564, 1535.416664666667, 614.7646579666666,\n",
       "        494.2115479666666, 777.1142292333334],\n",
       "       ['2016-09-30', 3094.84247, 1517.1542470000004, 617.4531078,\n",
       "        514.5374285, 763.9579941000002],\n",
       "       ['2016-10-31', 2941.914112333333, 1493.7506856666669,\n",
       "        601.3888980666667, 497.1393087333333, 725.2341621],\n",
       "       ['2016-11-30', 2788.9857546666667, 1470.347124333333,\n",
       "        585.3246883333334, 479.7411889666667, 686.5103301],\n",
       "       ['2016-12-31', 2636.057397, 1446.943563, 569.2604786, 462.3430692,\n",
       "        647.7864981],\n",
       "       ['2017-01-31', 2629.386708333333, 1421.7832626666666,\n",
       "        553.3237412999999, 463.41115033333335, 646.7970369666667],\n",
       "       ['2017-02-28', 2622.7160196666664, 1396.6229623333334,\n",
       "        537.3870039999998, 464.47923146666665, 645.8075758333333],\n",
       "       ['2017-03-31', 2616.045331, 1371.462662, 521.4502666999998,\n",
       "        465.5473126, 644.8181147000001],\n",
       "       ['2017-04-30', 2582.999953333333, 1385.6997396666666,\n",
       "        514.2855105000001, 456.63566276666666, 645.8685558666667],\n",
       "       ['2017-05-31', 2549.9545756666666, 1399.9368173333332,\n",
       "        507.12075430000004, 447.72401293333337, 646.9189970333333],\n",
       "       ['2017-06-30', 2516.909198, 1414.173895, 499.9559981, 438.8123631,\n",
       "        647.9694382],\n",
       "       ['2017-07-31', 2529.782464, 1411.1019353333334,\n",
       "        495.39090156666674, 419.9090564333334, 637.6159774666667],\n",
       "       ['2017-08-31', 2542.65573, 1408.0299756666666, 490.8258050333334,\n",
       "        401.00574976666667, 627.2625167333333],\n",
       "       ['2017-09-30', 2555.528996, 1404.958016, 486.2607085, 382.1024431,\n",
       "        616.909056],\n",
       "       ['2017-10-31', 2493.5604476666667, 1340.4287853333333,\n",
       "        485.59986143333333, 386.4377233, 608.7162381333333],\n",
       "       ['2017-11-30', 2431.591899333333, 1275.8995546666667,\n",
       "        484.9390143666667, 390.7730035, 600.5234202666667],\n",
       "       ['2017-12-31', 2369.623351, 1211.370324, 484.27816730000006,\n",
       "        395.1082837, 592.3306024],\n",
       "       ['2018-01-31', 2307.4944116666666, 1212.1657916666666,\n",
       "        479.0572197666667, 392.9066318, 605.3801967666667],\n",
       "       ['2018-02-28', 2245.365472333333, 1212.9612593333334,\n",
       "        473.83627223333326, 390.7049799, 618.4297911333333],\n",
       "       ['2018-03-31', 2183.236533, 1213.756727, 468.6153247, 388.503328,\n",
       "        631.4793855],\n",
       "       ['2018-04-30', 2086.8807423333333, 1146.0012783333334,\n",
       "        448.50893473333326, 390.50832306666666, 669.1150419666667],\n",
       "       ['2018-05-31', 1990.5249516666665, 1078.2458296666666,\n",
       "        428.40254476666667, 392.51331813333326, 706.7506984333335],\n",
       "       ['2018-06-30', 1894.169161, 1010.490381, 408.2961548, 394.5183132,\n",
       "        744.3863549],\n",
       "       ['2018-07-31', 1839.681530666667, 991.3822151, 434.8828281333333,\n",
       "        404.4480508333333, 756.4180495333335],\n",
       "       ['2018-08-31', 1785.1939003333332, 972.2740492,\n",
       "        461.46950146666666, 414.37778846666674, 768.4497441666666],\n",
       "       ['2018-09-30', 1730.70627, 953.1658833, 488.0561748, 424.3075261,\n",
       "        780.4814388],\n",
       "       ['2018-10-31', 1667.921494, 856.9003839999998, 471.2615347666666,\n",
       "        434.87458276666666, 773.9692328666665],\n",
       "       ['2018-11-30', 1605.136718, 760.6348846999998, 454.4668947333333,\n",
       "        445.44163943333336, 767.4570269333334],\n",
       "       ['2018-12-31', 1542.351942, 664.3693853999998, 437.67225470000005,\n",
       "        456.0086961, 760.944821],\n",
       "       ['2019-01-31', 1513.0525300000002, 657.3813301333333,\n",
       "        442.62654349999997, 467.28399896666673, 748.7807167999999],\n",
       "       ['2019-02-28', 1483.7531179999999, 650.3932748666666,\n",
       "        447.58083230000005, 478.5593018333333, 736.6166125999998],\n",
       "       ['2019-03-31', 1454.453706, 643.4052196, 452.5351211, 489.8346047,\n",
       "        724.4525083999998],\n",
       "       ['2019-04-30', 1394.134012, 601.7953597333334, 451.1815351333333,\n",
       "        506.34549253333336, 729.9813198666666],\n",
       "       ['2019-05-31', 1333.814318, 560.1854998666666, 449.8279491666667,\n",
       "        522.8563803666667, 735.5101313333333],\n",
       "       ['2019-06-30', 1273.494624, 518.57564, 448.4743632, 539.3672682,\n",
       "        741.0389428],\n",
       "       ['2019-07-31', 1254.7833143333332, 502.62033166666674,\n",
       "        447.61328139999995, 541.4308939333333, 740.6812809333335],\n",
       "       ['2019-08-31', 1236.0720046666665, 486.66502333333335,\n",
       "        446.7521996, 543.4945196666666, 740.3236190666668],\n",
       "       ['2019-09-30', 1217.360695, 470.709715, 445.8911178, 545.5581454,\n",
       "        739.9659572],\n",
       "       ['2019-10-31', 1182.1212549999998, 452.26334086666674,\n",
       "        441.0909160666667, 503.0336927333333, 736.5653751333334],\n",
       "       ['2019-11-30', 1146.881815, 433.81696673333335,\n",
       "        436.29071433333326, 460.5092400666666, 733.1647930666667],\n",
       "       ['2019-12-31', 1111.642375, 415.37059260000007, 431.4905126,\n",
       "        417.9847874, 729.764211],\n",
       "       ['2020-01-31', 1142.095113, 422.61892543333335,\n",
       "        430.13925353333326, 424.5219585333333, 737.7137843333335],\n",
       "       ['2020-02-29', 1172.547851, 429.86725826666674,\n",
       "        428.78799446666665, 431.0591296666667, 745.6633576666667],\n",
       "       ['2020-03-31', 1203.000589, 437.1155911, 427.43673539999986,\n",
       "        437.59630080000005, 753.612931]], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[:,1:5]\n",
    "Y = dataset[:,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scale = min_max_scaler.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.38276953, 0.48490881, 0.28760773, 1.        ],\n",
       "       [0.38286577, 0.49144556, 0.32225043, 0.9605532 ],\n",
       "       [0.38296201, 0.4979823 , 0.35689312, 0.92110641],\n",
       "       [0.38305824, 0.50451905, 0.39153581, 0.88165961],\n",
       "       [0.38098387, 0.51099945, 0.30995679, 0.58777307],\n",
       "       [0.3789095 , 0.51747985, 0.22837778, 0.29388654],\n",
       "       [0.37683513, 0.52396025, 0.14679876, 0.        ],\n",
       "       [0.36734818, 0.5186014 , 0.09786584, 0.0434695 ],\n",
       "       [0.35786123, 0.51324255, 0.04893292, 0.086939  ],\n",
       "       [0.34837428, 0.5078837 , 0.        , 0.1304085 ],\n",
       "       [0.36639744, 0.51287461, 0.05993416, 0.14266337],\n",
       "       [0.3844206 , 0.51786552, 0.11986831, 0.15491825],\n",
       "       [0.40244375, 0.52285643, 0.17980247, 0.16717312],\n",
       "       [0.36110259, 0.50921367, 0.15952074, 0.15377192],\n",
       "       [0.31976144, 0.49557092, 0.13923902, 0.14037072],\n",
       "       [0.27842028, 0.48192816, 0.1189573 , 0.12696952],\n",
       "       [0.29020478, 0.45689534, 0.12775618, 0.12639516],\n",
       "       [0.30198928, 0.43186251, 0.13655507, 0.1258208 ],\n",
       "       [0.31377379, 0.40682969, 0.14535396, 0.12524645],\n",
       "       [0.32908683, 0.39766203, 0.17879331, 0.12504798],\n",
       "       [0.34439986, 0.38849437, 0.21223267, 0.12484952],\n",
       "       [0.3597129 , 0.37932671, 0.24567202, 0.12465105],\n",
       "       [0.38311528, 0.38201793, 0.26898377, 0.13899188],\n",
       "       [0.40651766, 0.38470915, 0.29229552, 0.1533327 ],\n",
       "       [0.42992004, 0.38740037, 0.31560727, 0.16767352],\n",
       "       [0.39565395, 0.38312445, 0.31771115, 0.17102246],\n",
       "       [0.36138786, 0.37884854, 0.31981503, 0.1743714 ],\n",
       "       [0.32712176, 0.37457262, 0.32191891, 0.17772034],\n",
       "       [0.34361241, 0.3781905 , 0.37590033, 0.16918408],\n",
       "       [0.36010306, 0.38180838, 0.42988176, 0.16064782],\n",
       "       [0.3765937 , 0.38542626, 0.48386319, 0.15211155],\n",
       "       [0.37565953, 0.40924911, 0.42137913, 0.18968911],\n",
       "       [0.37472535, 0.43307197, 0.35889507, 0.22726666],\n",
       "       [0.37379118, 0.45689482, 0.29641102, 0.26484421],\n",
       "       [0.37686624, 0.394359  , 0.32575861, 0.27218252],\n",
       "       [0.3799413 , 0.33182319, 0.3551062 , 0.27952084],\n",
       "       [0.38301636, 0.26928737, 0.38445379, 0.28685915],\n",
       "       [0.38868168, 0.29195978, 0.42716844, 0.28832255],\n",
       "       [0.394347  , 0.31463219, 0.46988309, 0.28978595],\n",
       "       [0.40001231, 0.3373046 , 0.51259773, 0.29124936],\n",
       "       [0.37455353, 0.31821422, 0.48510399, 0.2922712 ],\n",
       "       [0.34909475, 0.29912385, 0.45761024, 0.29329304],\n",
       "       [0.32363597, 0.28003347, 0.4301165 , 0.29431489],\n",
       "       [0.32543034, 0.29600123, 0.44797618, 0.28115588],\n",
       "       [0.32722471, 0.31196899, 0.46583586, 0.26799687],\n",
       "       [0.32901908, 0.32793674, 0.48369555, 0.25483787],\n",
       "       [0.33171907, 0.34448894, 0.48776269, 0.26641758],\n",
       "       [0.33441905, 0.36104115, 0.49182984, 0.2779973 ],\n",
       "       [0.33711904, 0.37759335, 0.49589698, 0.28957702],\n",
       "       [0.32719494, 0.38593313, 0.47630548, 0.3036436 ],\n",
       "       [0.31727084, 0.39427291, 0.45671398, 0.31771019],\n",
       "       [0.30734674, 0.40261269, 0.43712248, 0.33177677],\n",
       "       [0.30228677, 0.41096915, 0.4036701 , 0.31584481],\n",
       "       [0.2972268 , 0.41932562, 0.37021773, 0.29991284],\n",
       "       [0.29216683, 0.42768208, 0.33676536, 0.28398088],\n",
       "       [0.3055205 , 0.43135757, 0.31046496, 0.28570662],\n",
       "       [0.31887416, 0.43503307, 0.28416457, 0.28743236],\n",
       "       [0.33222783, 0.43870856, 0.25786417, 0.2891581 ],\n",
       "       [0.30389285, 0.47565495, 0.29836928, 0.42623956],\n",
       "       [0.27555787, 0.51260134, 0.33887439, 0.56332102],\n",
       "       [0.24722289, 0.54954772, 0.3793795 , 0.70040248],\n",
       "       [0.31443637, 0.5525459 , 0.40598475, 0.70070225],\n",
       "       [0.38164985, 0.55554408, 0.43259   , 0.70100203],\n",
       "       [0.44886333, 0.55854227, 0.45919525, 0.70130181],\n",
       "       [0.49321782, 0.58887649, 0.46826847, 0.69781819],\n",
       "       [0.53757231, 0.61921072, 0.47734168, 0.69433458],\n",
       "       [0.58192679, 0.64954494, 0.4864149 , 0.69085096],\n",
       "       [0.70183016, 0.67327725, 0.59803869, 0.65473261],\n",
       "       [0.82173354, 0.69700956, 0.70966248, 0.61861427],\n",
       "       [0.94163691, 0.72074186, 0.82128627, 0.58249592],\n",
       "       [0.88770844, 0.73864864, 0.87774568, 0.58278676],\n",
       "       [0.83377997, 0.75655541, 0.93420509, 0.58307761],\n",
       "       [0.7798515 , 0.77446219, 0.9906645 , 0.58336845],\n",
       "       [0.85323433, 0.82232215, 0.99377633, 0.5692078 ],\n",
       "       [0.92661717, 0.87018212, 0.99688817, 0.55504714],\n",
       "       [1.        , 0.91804209, 1.        , 0.54088649],\n",
       "       [0.96553761, 0.9453614 , 0.92133861, 0.52386224],\n",
       "       [0.93107523, 0.9726807 , 0.84267722, 0.50683799],\n",
       "       [0.89661284, 1.        , 0.76401584, 0.48981373],\n",
       "       [0.92519927, 0.98420986, 0.77356422, 0.52393003],\n",
       "       [0.95378569, 0.96841972, 0.78311261, 0.55804632],\n",
       "       [0.98237212, 0.95262958, 0.792661  , 0.59216262],\n",
       "       [0.90661952, 0.93239428, 0.73560682, 0.56296047],\n",
       "       [0.83086693, 0.91215897, 0.67855264, 0.53375832],\n",
       "       [0.75511433, 0.89192367, 0.62149846, 0.50455617],\n",
       "       [0.75181003, 0.87016945, 0.56489702, 0.50634891],\n",
       "       [0.74850572, 0.84841523, 0.50829558, 0.50814165],\n",
       "       [0.74520141, 0.82666101, 0.45169414, 0.50993438],\n",
       "       [0.72883249, 0.83897074, 0.42624755, 0.49497649],\n",
       "       [0.71246356, 0.85128047, 0.40080097, 0.48001859],\n",
       "       [0.69609463, 0.8635902 , 0.37535438, 0.46506069],\n",
       "       [0.70247137, 0.86093411, 0.35914083, 0.43333214],\n",
       "       [0.7088481 , 0.85827802, 0.34292729, 0.40160358],\n",
       "       [0.71522483, 0.85562192, 0.32671374, 0.36987503],\n",
       "       [0.6845289 , 0.79982834, 0.32436665, 0.37715165],\n",
       "       [0.65383297, 0.74403476, 0.32201957, 0.38442827],\n",
       "       [0.62313704, 0.68824118, 0.31967248, 0.39170489],\n",
       "       [0.59236166, 0.68892897, 0.30112959, 0.38800949],\n",
       "       [0.56158628, 0.68961675, 0.2825867 , 0.38431409],\n",
       "       [0.5308109 , 0.69030453, 0.26404381, 0.3806187 ],\n",
       "       [0.48308135, 0.63172148, 0.19263329, 0.38398401],\n",
       "       [0.4353518 , 0.57313843, 0.12122277, 0.38734933],\n",
       "       [0.38762226, 0.51455538, 0.04981225, 0.39071464],\n",
       "       [0.36063197, 0.49803399, 0.14423836, 0.40738137],\n",
       "       [0.33364169, 0.48151259, 0.23866447, 0.42404809],\n",
       "       [0.30665141, 0.4649912 , 0.33309058, 0.44071482],\n",
       "       [0.27555116, 0.38175765, 0.27344218, 0.45845126],\n",
       "       [0.24445092, 0.2985241 , 0.21379378, 0.4761877 ],\n",
       "       [0.21335067, 0.21529056, 0.15414538, 0.49392414],\n",
       "       [0.1988373 , 0.20924851, 0.1717412 , 0.51284935],\n",
       "       [0.18432392, 0.20320646, 0.18933701, 0.53177456],\n",
       "       [0.16981055, 0.19716442, 0.20693283, 0.55069977],\n",
       "       [0.13993137, 0.16118749, 0.20212539, 0.57841273],\n",
       "       [0.11005219, 0.12521057, 0.19731795, 0.60612569],\n",
       "       [0.08017302, 0.08923365, 0.19251051, 0.63383865],\n",
       "       [0.07090443, 0.0754383 , 0.18945226, 0.63730238],\n",
       "       [0.06163584, 0.06164294, 0.18639401, 0.6407661 ],\n",
       "       [0.05236725, 0.04784758, 0.18333577, 0.64422983],\n",
       "       [0.0349115 , 0.03189839, 0.16628721, 0.57285399],\n",
       "       [0.01745575, 0.01594919, 0.14923866, 0.50147815],\n",
       "       [0.        , 0.        , 0.1321901 , 0.43010232],\n",
       "       [0.01508467, 0.00626709, 0.12739093, 0.44107473],\n",
       "       [0.03016934, 0.01253418, 0.12259175, 0.45204715],\n",
       "       [0.04525401, 0.01880127, 0.11779257, 0.46301957]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99, 4) (12, 4) (13, 4) (99,) (12,) (13,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val_and_test, Y_train, Y_val_and_test = train_test_split(X_scale, Y, test_size=0.2)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_val_and_test, Y_val_and_test, test_size=0.5)\n",
    "print(X_train.shape, X_val.shape, X_test.shape, Y_train.shape, Y_val.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Dense(6, activation='softplus', input_shape=(4,)),\n",
    "    Dense(32, activation='softplus'),\n",
    "    Dense(12, activation='softplus'),\n",
    "    Dense(1, activation='softplus'),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam',\n",
    "              loss='mean_absolute_error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 99 samples, validate on 12 samples\n",
      "Epoch 1/500\n",
      "99/99 [==============================] - 0s 2ms/step - loss: 743.0129 - val_loss: 766.1978\n",
      "Epoch 2/500\n",
      "99/99 [==============================] - 0s 51us/step - loss: 742.9939 - val_loss: 766.1808\n",
      "Epoch 3/500\n",
      "99/99 [==============================] - 0s 50us/step - loss: 742.9771 - val_loss: 766.1621\n",
      "Epoch 4/500\n",
      "99/99 [==============================] - 0s 61us/step - loss: 742.9584 - val_loss: 766.1421\n",
      "Epoch 5/500\n",
      "99/99 [==============================] - 0s 50us/step - loss: 742.9385 - val_loss: 766.1198\n",
      "Epoch 6/500\n",
      "99/99 [==============================] - 0s 31us/step - loss: 742.9162 - val_loss: 766.0974\n",
      "Epoch 7/500\n",
      "99/99 [==============================] - 0s 41us/step - loss: 742.8938 - val_loss: 766.0735\n",
      "Epoch 8/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 742.8702 - val_loss: 766.0486\n",
      "Epoch 9/500\n",
      "99/99 [==============================] - 0s 51us/step - loss: 742.8453 - val_loss: 766.0226\n",
      "Epoch 10/500\n",
      "99/99 [==============================] - 0s 50us/step - loss: 742.8193 - val_loss: 765.9954\n",
      "Epoch 11/500\n",
      "99/99 [==============================] - 0s 61us/step - loss: 742.7921 - val_loss: 765.9668\n",
      "Epoch 12/500\n",
      "99/99 [==============================] - 0s 51us/step - loss: 742.7637 - val_loss: 765.9370\n",
      "Epoch 13/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 742.7341 - val_loss: 765.9058\n",
      "Epoch 14/500\n",
      "99/99 [==============================] - 0s 51us/step - loss: 742.7031 - val_loss: 765.8734\n",
      "Epoch 15/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 742.6705 - val_loss: 765.8397\n",
      "Epoch 16/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 742.6370 - val_loss: 765.8044\n",
      "Epoch 17/500\n",
      "99/99 [==============================] - 0s 51us/step - loss: 742.6019 - val_loss: 765.7676\n",
      "Epoch 18/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 742.5652 - val_loss: 765.7292\n",
      "Epoch 19/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 742.5270 - val_loss: 765.6895\n",
      "Epoch 20/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 742.4873 - val_loss: 765.6484\n",
      "Epoch 21/500\n",
      "99/99 [==============================] - 0s 51us/step - loss: 742.4464 - val_loss: 765.6055\n",
      "Epoch 22/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 742.4035 - val_loss: 765.5612\n",
      "Epoch 23/500\n",
      "99/99 [==============================] - 0s 51us/step - loss: 742.3594 - val_loss: 765.5147\n",
      "Epoch 24/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 742.3133 - val_loss: 765.4666\n",
      "Epoch 25/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 742.2653 - val_loss: 765.4167\n",
      "Epoch 26/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 742.2155 - val_loss: 765.3657\n",
      "Epoch 27/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 742.1646 - val_loss: 765.3120\n",
      "Epoch 28/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 742.1113 - val_loss: 765.2567\n",
      "Epoch 29/500\n",
      "99/99 [==============================] - 0s 51us/step - loss: 742.0561 - val_loss: 765.2000\n",
      "Epoch 30/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 741.9996 - val_loss: 765.1408\n",
      "Epoch 31/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 741.9407 - val_loss: 765.0804\n",
      "Epoch 32/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 741.8804 - val_loss: 765.0173\n",
      "Epoch 33/500\n",
      "99/99 [==============================] - 0s 51us/step - loss: 741.8176 - val_loss: 764.9529\n",
      "Epoch 34/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 741.7535 - val_loss: 764.8858\n",
      "Epoch 35/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 741.6865 - val_loss: 764.8176\n",
      "Epoch 36/500\n",
      "99/99 [==============================] - 0s 50us/step - loss: 741.6186 - val_loss: 764.7465\n",
      "Epoch 37/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 741.5479 - val_loss: 764.6734\n",
      "Epoch 38/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 741.4750 - val_loss: 764.5983\n",
      "Epoch 39/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 741.4001 - val_loss: 764.5220\n",
      "Epoch 40/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 741.3241 - val_loss: 764.4429\n",
      "Epoch 41/500\n",
      "99/99 [==============================] - 0s 50us/step - loss: 741.2454 - val_loss: 764.3616\n",
      "Epoch 42/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 741.1644 - val_loss: 764.2784\n",
      "Epoch 43/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 741.0815 - val_loss: 764.1940\n",
      "Epoch 44/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 740.9975 - val_loss: 764.1068\n",
      "Epoch 45/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 740.9105 - val_loss: 764.0173\n",
      "Epoch 46/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 740.8216 - val_loss: 763.9260\n",
      "Epoch 47/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 740.7307 - val_loss: 763.8327\n",
      "Epoch 48/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 740.6377 - val_loss: 763.7372\n",
      "Epoch 49/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 740.5426 - val_loss: 763.6398\n",
      "Epoch 50/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 740.4456 - val_loss: 763.5413\n",
      "Epoch 51/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 740.3475 - val_loss: 763.4398\n",
      "Epoch 52/500\n",
      "99/99 [==============================] - 0s 51us/step - loss: 740.2464 - val_loss: 763.3362\n",
      "Epoch 53/500\n",
      "99/99 [==============================] - 0s 51us/step - loss: 740.1434 - val_loss: 763.2307\n",
      "Epoch 54/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 740.0383 - val_loss: 763.1230\n",
      "Epoch 55/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 739.9312 - val_loss: 763.0134\n",
      "Epoch 56/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 739.8221 - val_loss: 762.9017\n",
      "Epoch 57/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 739.7109 - val_loss: 762.7880\n",
      "Epoch 58/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 739.5977 - val_loss: 762.6721\n",
      "Epoch 59/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 739.4825 - val_loss: 762.5542\n",
      "Epoch 60/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 739.3652 - val_loss: 762.4343\n",
      "Epoch 61/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 739.2458 - val_loss: 762.3122\n",
      "Epoch 62/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 739.1245 - val_loss: 762.1880\n",
      "Epoch 63/500\n",
      "99/99 [==============================] - 0s 51us/step - loss: 739.0009 - val_loss: 762.0617\n",
      "Epoch 64/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 738.8752 - val_loss: 761.9341\n",
      "Epoch 65/500\n",
      "99/99 [==============================] - 0s 61us/step - loss: 738.7485 - val_loss: 761.8035\n",
      "Epoch 66/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 738.6185 - val_loss: 761.6707\n",
      "Epoch 67/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 738.4866 - val_loss: 761.5356\n",
      "Epoch 68/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 738.3524 - val_loss: 761.3984\n",
      "Epoch 69/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 738.2159 - val_loss: 761.2589\n",
      "Epoch 70/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 738.0773 - val_loss: 761.1180\n",
      "Epoch 71/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 737.9373 - val_loss: 760.9739\n",
      "Epoch 72/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 737.7942 - val_loss: 760.8273\n",
      "Epoch 73/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 737.6486 - val_loss: 760.6784\n",
      "Epoch 74/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 737.5006 - val_loss: 760.5270\n",
      "Epoch 75/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 737.3504 - val_loss: 760.3732\n",
      "Epoch 76/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 737.1976 - val_loss: 760.2169\n",
      "Epoch 77/500\n",
      "99/99 [==============================] - 0s 51us/step - loss: 737.0424 - val_loss: 760.0579\n",
      "Epoch 78/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 736.8846 - val_loss: 759.8974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 79/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 736.7253 - val_loss: 759.7332\n",
      "Epoch 80/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 736.5623 - val_loss: 759.5672\n",
      "Epoch 81/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 736.3977 - val_loss: 759.3976\n",
      "Epoch 82/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 736.2293 - val_loss: 759.2251\n",
      "Epoch 83/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 736.0583 - val_loss: 759.0496\n",
      "Epoch 84/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 735.8843 - val_loss: 758.8714\n",
      "Epoch 85/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 735.7075 - val_loss: 758.6901\n",
      "Epoch 86/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 735.5278 - val_loss: 758.5058\n",
      "Epoch 87/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 735.3450 - val_loss: 758.3183\n",
      "Epoch 88/500\n",
      "99/99 [==============================] - 0s 51us/step - loss: 735.1592 - val_loss: 758.1287\n",
      "Epoch 89/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 734.9714 - val_loss: 757.9348\n",
      "Epoch 90/500\n",
      "99/99 [==============================] - 0s 32us/step - loss: 734.7792 - val_loss: 757.7375\n",
      "Epoch 91/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 734.5839 - val_loss: 757.5369\n",
      "Epoch 92/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 734.3852 - val_loss: 757.3329\n",
      "Epoch 93/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 734.1832 - val_loss: 757.1253\n",
      "Epoch 94/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 733.9776 - val_loss: 756.9142\n",
      "Epoch 95/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 733.7686 - val_loss: 756.6993\n",
      "Epoch 96/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 733.5558 - val_loss: 756.4807\n",
      "Epoch 97/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 733.3395 - val_loss: 756.2583\n",
      "Epoch 98/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 733.1194 - val_loss: 756.0319\n",
      "Epoch 99/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 732.8956 - val_loss: 755.8027\n",
      "Epoch 100/500\n",
      "99/99 [==============================] - 0s 61us/step - loss: 732.6689 - val_loss: 755.5683\n",
      "Epoch 101/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 732.4370 - val_loss: 755.3297\n",
      "Epoch 102/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 732.2012 - val_loss: 755.0869\n",
      "Epoch 103/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 731.9610 - val_loss: 754.8408\n",
      "Epoch 104/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 731.7178 - val_loss: 754.5892\n",
      "Epoch 105/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 731.4692 - val_loss: 754.3330\n",
      "Epoch 106/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 731.2161 - val_loss: 754.0723\n",
      "Epoch 107/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 730.9587 - val_loss: 753.8068\n",
      "Epoch 108/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 730.6965 - val_loss: 753.5378\n",
      "Epoch 109/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 730.4307 - val_loss: 753.2637\n",
      "Epoch 110/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 730.1602 - val_loss: 752.9836\n",
      "Epoch 111/500\n",
      "99/99 [==============================] - 0s 41us/step - loss: 729.8836 - val_loss: 752.6983\n",
      "Epoch 112/500\n",
      "99/99 [==============================] - 0s 51us/step - loss: 729.6021 - val_loss: 752.4078\n",
      "Epoch 113/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 729.3154 - val_loss: 752.1120\n",
      "Epoch 114/500\n",
      "99/99 [==============================] - 0s 51us/step - loss: 729.0234 - val_loss: 751.8118\n",
      "Epoch 115/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 728.7275 - val_loss: 751.5063\n",
      "Epoch 116/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 728.4262 - val_loss: 751.1938\n",
      "Epoch 117/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 728.1182 - val_loss: 750.8757\n",
      "Epoch 118/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 727.8043 - val_loss: 750.5515\n",
      "Epoch 119/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 727.4849 - val_loss: 750.2214\n",
      "Epoch 120/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 727.1594 - val_loss: 749.8851\n",
      "Epoch 121/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 726.8281 - val_loss: 749.5425\n",
      "Epoch 122/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 726.4907 - val_loss: 749.1935\n",
      "Epoch 123/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 726.1469 - val_loss: 748.8381\n",
      "Epoch 124/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 725.7968 - val_loss: 748.4760\n",
      "Epoch 125/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 725.4402 - val_loss: 748.1071\n",
      "Epoch 126/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 725.0771 - val_loss: 747.7313\n",
      "Epoch 127/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 724.7073 - val_loss: 747.3484\n",
      "Epoch 128/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 724.3306 - val_loss: 746.9585\n",
      "Epoch 129/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 723.9468 - val_loss: 746.5626\n",
      "Epoch 130/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 723.5573 - val_loss: 746.1577\n",
      "Epoch 131/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 723.1592 - val_loss: 745.7454\n",
      "Epoch 132/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 722.7536 - val_loss: 745.3252\n",
      "Epoch 133/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 722.3405 - val_loss: 744.8986\n",
      "Epoch 134/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 721.9211 - val_loss: 744.4641\n",
      "Epoch 135/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 721.4941 - val_loss: 744.0198\n",
      "Epoch 136/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 721.0574 - val_loss: 743.5672\n",
      "Epoch 137/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 720.6127 - val_loss: 743.1060\n",
      "Epoch 138/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 720.1597 - val_loss: 742.6362\n",
      "Epoch 139/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 719.6981 - val_loss: 742.1590\n",
      "Epoch 140/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 719.2297 - val_loss: 741.6713\n",
      "Epoch 141/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 718.7508 - val_loss: 741.1745\n",
      "Epoch 142/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 718.2631 - val_loss: 740.6682\n",
      "Epoch 143/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 717.7662 - val_loss: 740.1525\n",
      "Epoch 144/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 717.2600 - val_loss: 739.6287\n",
      "Epoch 145/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 716.7462 - val_loss: 739.0935\n",
      "Epoch 146/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 716.2210 - val_loss: 738.5482\n",
      "Epoch 147/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 715.6861 - val_loss: 737.9925\n",
      "Epoch 148/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 715.1412 - val_loss: 737.4266\n",
      "Epoch 149/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 714.5862 - val_loss: 736.8517\n",
      "Epoch 150/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 714.0226 - val_loss: 736.2643\n",
      "Epoch 151/500\n",
      "99/99 [==============================] - 0s 51us/step - loss: 713.4469 - val_loss: 735.6660\n",
      "Epoch 152/500\n",
      "99/99 [==============================] - 0s 51us/step - loss: 712.8604 - val_loss: 735.0564\n",
      "Epoch 153/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 712.2630 - val_loss: 734.4354\n",
      "Epoch 154/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 711.6547 - val_loss: 733.8029\n",
      "Epoch 155/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 711.0350 - val_loss: 733.1605\n",
      "Epoch 156/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 710.4057 - val_loss: 732.5062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 157/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 709.7650 - val_loss: 731.8376\n",
      "Epoch 158/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 709.1104 - val_loss: 731.1567\n",
      "Epoch 159/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 708.4437 - val_loss: 730.4632\n",
      "Epoch 160/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 707.7649 - val_loss: 729.7589\n",
      "Epoch 161/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 707.0754 - val_loss: 729.0395\n",
      "Epoch 162/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 706.3715 - val_loss: 728.3089\n",
      "Epoch 163/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 705.6566 - val_loss: 727.5627\n",
      "Epoch 164/500\n",
      "99/99 [==============================] - 0s 61us/step - loss: 704.9266 - val_loss: 726.8027\n",
      "Epoch 165/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 704.1833 - val_loss: 726.0289\n",
      "Epoch 166/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 703.4265 - val_loss: 725.2408\n",
      "Epoch 167/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 702.6558 - val_loss: 724.4383\n",
      "Epoch 168/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 701.8710 - val_loss: 723.6211\n",
      "Epoch 169/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 701.0721 - val_loss: 722.7889\n",
      "Epoch 170/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 700.2587 - val_loss: 721.9416\n",
      "Epoch 171/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 699.4307 - val_loss: 721.0789\n",
      "Epoch 172/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 698.5876 - val_loss: 720.2004\n",
      "Epoch 173/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 697.7293 - val_loss: 719.3062\n",
      "Epoch 174/500\n",
      "99/99 [==============================] - 0s 51us/step - loss: 696.8556 - val_loss: 718.3956\n",
      "Epoch 175/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 695.9661 - val_loss: 717.4686\n",
      "Epoch 176/500\n",
      "99/99 [==============================] - 0s 51us/step - loss: 695.0609 - val_loss: 716.5249\n",
      "Epoch 177/500\n",
      "99/99 [==============================] - 0s 51us/step - loss: 694.1393 - val_loss: 715.5642\n",
      "Epoch 178/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 693.2013 - val_loss: 714.5862\n",
      "Epoch 179/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 692.2466 - val_loss: 713.5908\n",
      "Epoch 180/500\n",
      "99/99 [==============================] - 0s 51us/step - loss: 691.2748 - val_loss: 712.5776\n",
      "Epoch 181/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 690.2858 - val_loss: 711.5488\n",
      "Epoch 182/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 689.2818 - val_loss: 710.4991\n",
      "Epoch 183/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 688.2576 - val_loss: 709.4334\n",
      "Epoch 184/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 687.2178 - val_loss: 708.3462\n",
      "Epoch 185/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 686.1572 - val_loss: 707.2398\n",
      "Epoch 186/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 685.0779 - val_loss: 706.1138\n",
      "Epoch 187/500\n",
      "99/99 [==============================] - 0s 51us/step - loss: 683.9799 - val_loss: 704.9680\n",
      "Epoch 188/500\n",
      "99/99 [==============================] - 0s 51us/step - loss: 682.8625 - val_loss: 703.8021\n",
      "Epoch 189/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 681.7257 - val_loss: 702.6157\n",
      "Epoch 190/500\n",
      "99/99 [==============================] - 0s 51us/step - loss: 680.5690 - val_loss: 701.4086\n",
      "Epoch 191/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 679.3923 - val_loss: 700.1804\n",
      "Epoch 192/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 678.1953 - val_loss: 698.9308\n",
      "Epoch 193/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 676.9774 - val_loss: 697.6595\n",
      "Epoch 194/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 675.7386 - val_loss: 696.3662\n",
      "Epoch 195/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 674.4785 - val_loss: 695.0505\n",
      "Epoch 196/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 673.1967 - val_loss: 693.7122\n",
      "Epoch 197/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 671.8929 - val_loss: 692.3508\n",
      "Epoch 198/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 670.5669 - val_loss: 690.9660\n",
      "Epoch 199/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 669.2184 - val_loss: 689.5576\n",
      "Epoch 200/500\n",
      "99/99 [==============================] - 0s 50us/step - loss: 667.8468 - val_loss: 688.1250\n",
      "Epoch 201/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 666.4520 - val_loss: 686.6682\n",
      "Epoch 202/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 665.0335 - val_loss: 685.1865\n",
      "Epoch 203/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 663.5913 - val_loss: 683.6796\n",
      "Epoch 204/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 662.1247 - val_loss: 682.1474\n",
      "Epoch 205/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 660.6335 - val_loss: 680.5893\n",
      "Epoch 206/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 659.1172 - val_loss: 679.0050\n",
      "Epoch 207/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 657.5757 - val_loss: 677.3941\n",
      "Epoch 208/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 656.0085 - val_loss: 675.7563\n",
      "Epoch 209/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 654.4152 - val_loss: 674.0911\n",
      "Epoch 210/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 652.7955 - val_loss: 672.3983\n",
      "Epoch 211/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 651.1490 - val_loss: 670.6773\n",
      "Epoch 212/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 649.4755 - val_loss: 668.9278\n",
      "Epoch 213/500\n",
      "99/99 [==============================] - 0s 51us/step - loss: 647.7744 - val_loss: 667.1495\n",
      "Epoch 214/500\n",
      "99/99 [==============================] - 0s 41us/step - loss: 646.0453 - val_loss: 665.3419\n",
      "Epoch 215/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 644.2881 - val_loss: 663.5046\n",
      "Epoch 216/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 642.5022 - val_loss: 661.6372\n",
      "Epoch 217/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 640.6871 - val_loss: 659.7393\n",
      "Epoch 218/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 638.8428 - val_loss: 657.8105\n",
      "Epoch 219/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 636.9684 - val_loss: 655.8505\n",
      "Epoch 220/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 635.0640 - val_loss: 653.8587\n",
      "Epoch 221/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 633.1288 - val_loss: 651.8347\n",
      "Epoch 222/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 631.1628 - val_loss: 649.7782\n",
      "Epoch 223/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 629.1652 - val_loss: 647.6887\n",
      "Epoch 224/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 627.1359 - val_loss: 645.5657\n",
      "Epoch 225/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 625.0742 - val_loss: 643.4089\n",
      "Epoch 226/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 622.9799 - val_loss: 641.2178\n",
      "Epoch 227/500\n",
      "99/99 [==============================] - 0s 50us/step - loss: 620.8525 - val_loss: 638.9920\n",
      "Epoch 228/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 618.6916 - val_loss: 636.7310\n",
      "Epoch 229/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 616.4967 - val_loss: 634.4344\n",
      "Epoch 230/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 614.2676 - val_loss: 632.1017\n",
      "Epoch 231/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 612.0036 - val_loss: 629.7325\n",
      "Epoch 232/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 609.7045 - val_loss: 627.3264\n",
      "Epoch 233/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 607.3697 - val_loss: 624.8827\n",
      "Epoch 234/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 604.9988 - val_loss: 622.4012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 235/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 602.5914 - val_loss: 619.8814\n",
      "Epoch 236/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 600.1470 - val_loss: 617.3228\n",
      "Epoch 237/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 597.6653 - val_loss: 614.7249\n",
      "Epoch 238/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 595.1457 - val_loss: 612.0872\n",
      "Epoch 239/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 592.5878 - val_loss: 609.4094\n",
      "Epoch 240/500\n",
      "99/99 [==============================] - 0s 51us/step - loss: 589.9911 - val_loss: 606.6909\n",
      "Epoch 241/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 587.3553 - val_loss: 603.9312\n",
      "Epoch 242/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 584.6798 - val_loss: 601.1299\n",
      "Epoch 243/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 581.9642 - val_loss: 598.2864\n",
      "Epoch 244/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 579.2081 - val_loss: 595.4005\n",
      "Epoch 245/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 576.4109 - val_loss: 592.4714\n",
      "Epoch 246/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 573.5723 - val_loss: 589.4988\n",
      "Epoch 247/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 570.6918 - val_loss: 586.4821\n",
      "Epoch 248/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 567.7688 - val_loss: 583.4210\n",
      "Epoch 249/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 564.8030 - val_loss: 580.3148\n",
      "Epoch 250/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 561.7938 - val_loss: 577.1631\n",
      "Epoch 251/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 558.7408 - val_loss: 573.9655\n",
      "Epoch 252/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 555.6435 - val_loss: 570.7213\n",
      "Epoch 253/500\n",
      "99/99 [==============================] - 0s 41us/step - loss: 552.5016 - val_loss: 567.4302\n",
      "Epoch 254/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 549.3143 - val_loss: 564.0916\n",
      "Epoch 255/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 546.0814 - val_loss: 560.7051\n",
      "Epoch 256/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 542.8023 - val_loss: 557.2701\n",
      "Epoch 257/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 539.4767 - val_loss: 553.7862\n",
      "Epoch 258/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 536.1038 - val_loss: 550.2529\n",
      "Epoch 259/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 532.6834 - val_loss: 546.6695\n",
      "Epoch 260/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 529.2150 - val_loss: 543.0357\n",
      "Epoch 261/500\n",
      "99/99 [==============================] - 0s 50us/step - loss: 525.6979 - val_loss: 539.3510\n",
      "Epoch 262/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 522.1319 - val_loss: 535.6148\n",
      "Epoch 263/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 518.5164 - val_loss: 531.8266\n",
      "Epoch 264/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 514.8508 - val_loss: 527.9860\n",
      "Epoch 265/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 511.1348 - val_loss: 524.0923\n",
      "Epoch 266/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 507.3678 - val_loss: 520.1453\n",
      "Epoch 267/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 503.5493 - val_loss: 516.1442\n",
      "Epoch 268/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 499.6791 - val_loss: 512.0887\n",
      "Epoch 269/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 495.7563 - val_loss: 507.9781\n",
      "Epoch 270/500\n",
      "99/99 [==============================] - 0s 61us/step - loss: 491.7806 - val_loss: 503.8120\n",
      "Epoch 271/500\n",
      "99/99 [==============================] - 0s 61us/step - loss: 487.7516 - val_loss: 499.5900\n",
      "Epoch 272/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 483.6687 - val_loss: 495.3114\n",
      "Epoch 273/500\n",
      "99/99 [==============================] - 0s 41us/step - loss: 479.5314 - val_loss: 490.9757\n",
      "Epoch 274/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 475.3393 - val_loss: 486.5825\n",
      "Epoch 275/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 471.0917 - val_loss: 482.1312\n",
      "Epoch 276/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 466.7884 - val_loss: 477.6213\n",
      "Epoch 277/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 462.4287 - val_loss: 473.0523\n",
      "Epoch 278/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 458.0122 - val_loss: 468.4237\n",
      "Epoch 279/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 453.5385 - val_loss: 463.7350\n",
      "Epoch 280/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 449.0067 - val_loss: 458.9856\n",
      "Epoch 281/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 444.4168 - val_loss: 454.1751\n",
      "Epoch 282/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 439.7681 - val_loss: 449.3028\n",
      "Epoch 283/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 435.0599 - val_loss: 444.3684\n",
      "Epoch 284/500\n",
      "99/99 [==============================] - 0s 61us/step - loss: 430.2921 - val_loss: 439.3712\n",
      "Epoch 285/500\n",
      "99/99 [==============================] - 0s 51us/step - loss: 425.4639 - val_loss: 434.3106\n",
      "Epoch 286/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 420.5749 - val_loss: 429.1864\n",
      "Epoch 287/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 415.6246 - val_loss: 423.9977\n",
      "Epoch 288/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 410.6124 - val_loss: 418.7443\n",
      "Epoch 289/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 405.5380 - val_loss: 413.4254\n",
      "Epoch 290/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 400.4007 - val_loss: 408.0407\n",
      "Epoch 291/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 395.2000 - val_loss: 402.5895\n",
      "Epoch 292/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 389.9355 - val_loss: 397.0714\n",
      "Epoch 293/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 384.6067 - val_loss: 391.4857\n",
      "Epoch 294/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 379.2130 - val_loss: 385.8320\n",
      "Epoch 295/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 373.7538 - val_loss: 380.1097\n",
      "Epoch 296/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 368.2289 - val_loss: 374.3184\n",
      "Epoch 297/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 362.6375 - val_loss: 368.4573\n",
      "Epoch 298/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 356.9792 - val_loss: 362.5260\n",
      "Epoch 299/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 351.2534 - val_loss: 356.5240\n",
      "Epoch 300/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 345.4596 - val_loss: 350.4507\n",
      "Epoch 301/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 339.5974 - val_loss: 344.3056\n",
      "Epoch 302/500\n",
      "99/99 [==============================] - 0s 41us/step - loss: 333.6662 - val_loss: 338.0880\n",
      "Epoch 303/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 327.6654 - val_loss: 331.7976\n",
      "Epoch 304/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 321.5946 - val_loss: 325.4337\n",
      "Epoch 305/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 315.4532 - val_loss: 318.9957\n",
      "Epoch 306/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 309.2408 - val_loss: 312.4832\n",
      "Epoch 307/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 302.9566 - val_loss: 305.8955\n",
      "Epoch 308/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 296.6003 - val_loss: 299.2321\n",
      "Epoch 309/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 290.1712 - val_loss: 292.4924\n",
      "Epoch 310/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 283.6690 - val_loss: 285.6759\n",
      "Epoch 311/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 277.0930 - val_loss: 278.7820\n",
      "Epoch 312/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 270.4426 - val_loss: 271.8102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 313/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 263.7174 - val_loss: 264.7598\n",
      "Epoch 314/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 256.9168 - val_loss: 257.6304\n",
      "Epoch 315/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 250.0403 - val_loss: 250.4213\n",
      "Epoch 316/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 243.0873 - val_loss: 243.1320\n",
      "Epoch 317/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 236.2702 - val_loss: 235.7968\n",
      "Epoch 318/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 229.9574 - val_loss: 229.3216\n",
      "Epoch 319/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 224.7841 - val_loss: 225.3008\n",
      "Epoch 320/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 220.5981 - val_loss: 224.0004\n",
      "Epoch 321/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 216.7544 - val_loss: 223.0943\n",
      "Epoch 322/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 213.4016 - val_loss: 222.2122\n",
      "Epoch 323/500\n",
      "99/99 [==============================] - 0s 51us/step - loss: 210.5885 - val_loss: 221.3566\n",
      "Epoch 324/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 208.1161 - val_loss: 220.5269\n",
      "Epoch 325/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 205.8364 - val_loss: 219.7228\n",
      "Epoch 326/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 203.7449 - val_loss: 218.9414\n",
      "Epoch 327/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 201.7948 - val_loss: 218.1826\n",
      "Epoch 328/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 199.9570 - val_loss: 217.4438\n",
      "Epoch 329/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 198.3054 - val_loss: 216.7254\n",
      "Epoch 330/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 196.7151 - val_loss: 216.0251\n",
      "Epoch 331/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 195.1723 - val_loss: 215.3407\n",
      "Epoch 332/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 193.6719 - val_loss: 214.6703\n",
      "Epoch 333/500\n",
      "99/99 [==============================] - 0s 51us/step - loss: 192.2089 - val_loss: 214.0120\n",
      "Epoch 334/500\n",
      "99/99 [==============================] - 0s 51us/step - loss: 190.7788 - val_loss: 213.3642\n",
      "Epoch 335/500\n",
      "99/99 [==============================] - 0s 51us/step - loss: 189.3777 - val_loss: 212.7255\n",
      "Epoch 336/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 188.0017 - val_loss: 212.0946\n",
      "Epoch 337/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 186.7381 - val_loss: 211.4733\n",
      "Epoch 338/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 185.5125 - val_loss: 210.8603\n",
      "Epoch 339/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 184.3081 - val_loss: 210.2545\n",
      "Epoch 340/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 183.1220 - val_loss: 209.6546\n",
      "Epoch 341/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 181.9517 - val_loss: 209.0597\n",
      "Epoch 342/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 180.7948 - val_loss: 208.4689\n",
      "Epoch 343/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 179.6494 - val_loss: 207.8813\n",
      "Epoch 344/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 178.5135 - val_loss: 207.2962\n",
      "Epoch 345/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 177.3855 - val_loss: 206.7129\n",
      "Epoch 346/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 176.2820 - val_loss: 206.1335\n",
      "Epoch 347/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 175.3075 - val_loss: 205.5664\n",
      "Epoch 348/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 174.5064 - val_loss: 205.0101\n",
      "Epoch 349/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 173.7231 - val_loss: 204.4632\n",
      "Epoch 350/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 173.0040 - val_loss: 203.9274\n",
      "Epoch 351/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 172.3118 - val_loss: 203.4011\n",
      "Epoch 352/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 171.6340 - val_loss: 202.8832\n",
      "Epoch 353/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 170.9689 - val_loss: 202.3726\n",
      "Epoch 354/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 170.3147 - val_loss: 201.8683\n",
      "Epoch 355/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 169.6702 - val_loss: 201.3693\n",
      "Epoch 356/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 169.0340 - val_loss: 200.8749\n",
      "Epoch 357/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 168.4084 - val_loss: 200.3880\n",
      "Epoch 358/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 167.8535 - val_loss: 199.9077\n",
      "Epoch 359/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 167.3456 - val_loss: 199.4359\n",
      "Epoch 360/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 166.8565 - val_loss: 198.9717\n",
      "Epoch 361/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 166.3759 - val_loss: 198.5140\n",
      "Epoch 362/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 165.9028 - val_loss: 198.0619\n",
      "Epoch 363/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 165.4792 - val_loss: 197.6179\n",
      "Epoch 364/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 165.0966 - val_loss: 197.1847\n",
      "Epoch 365/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 164.7433 - val_loss: 196.7613\n",
      "Epoch 366/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 164.3974 - val_loss: 196.3464\n",
      "Epoch 367/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 164.0582 - val_loss: 195.9390\n",
      "Epoch 368/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 163.7247 - val_loss: 195.5383\n",
      "Epoch 369/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 163.3964 - val_loss: 195.1434\n",
      "Epoch 370/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 163.0725 - val_loss: 194.7535\n",
      "Epoch 371/500\n",
      "99/99 [==============================] - 0s 51us/step - loss: 162.7827 - val_loss: 194.3713\n",
      "Epoch 372/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 162.5384 - val_loss: 193.9998\n",
      "Epoch 373/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 162.3020 - val_loss: 193.6379\n",
      "Epoch 374/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 162.0700 - val_loss: 193.2845\n",
      "Epoch 375/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 161.8440 - val_loss: 192.9424\n",
      "Epoch 376/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 161.6510 - val_loss: 192.6104\n",
      "Epoch 377/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 161.4612 - val_loss: 192.2874\n",
      "Epoch 378/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 161.2741 - val_loss: 191.9724\n",
      "Epoch 379/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 161.0894 - val_loss: 191.6646\n",
      "Epoch 380/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 160.9068 - val_loss: 191.3631\n",
      "Epoch 381/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 160.7262 - val_loss: 191.0673\n",
      "Epoch 382/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 160.5470 - val_loss: 190.7764\n",
      "Epoch 383/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 160.3820 - val_loss: 190.4943\n",
      "Epoch 384/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 160.2293 - val_loss: 190.2198\n",
      "Epoch 385/500\n",
      "99/99 [==============================] - 0s 51us/step - loss: 160.0777 - val_loss: 189.9524\n",
      "Epoch 386/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 159.9270 - val_loss: 189.6912\n",
      "Epoch 387/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 159.7771 - val_loss: 189.4354\n",
      "Epoch 388/500\n",
      "99/99 [==============================] - 0s 61us/step - loss: 159.6279 - val_loss: 189.1848\n",
      "Epoch 389/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 159.4794 - val_loss: 188.9383\n",
      "Epoch 390/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 159.3312 - val_loss: 188.6956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 391/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 159.1834 - val_loss: 188.4564\n",
      "Epoch 392/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 159.0359 - val_loss: 188.2201\n",
      "Epoch 393/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 158.8887 - val_loss: 187.9863\n",
      "Epoch 394/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 158.7523 - val_loss: 187.7585\n",
      "Epoch 395/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 158.6175 - val_loss: 187.5358\n",
      "Epoch 396/500\n",
      "99/99 [==============================] - 0s 61us/step - loss: 158.4828 - val_loss: 187.3178\n",
      "Epoch 397/500\n",
      "99/99 [==============================] - 0s 51us/step - loss: 158.3483 - val_loss: 187.1039\n",
      "Epoch 398/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 158.2138 - val_loss: 186.8936\n",
      "Epoch 399/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 158.0794 - val_loss: 186.6866\n",
      "Epoch 400/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 157.9451 - val_loss: 186.4824\n",
      "Epoch 401/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 157.8107 - val_loss: 186.2808\n",
      "Epoch 402/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 157.6787 - val_loss: 186.0853\n",
      "Epoch 403/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 157.5564 - val_loss: 185.8989\n",
      "Epoch 404/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 157.4339 - val_loss: 185.7209\n",
      "Epoch 405/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 157.3099 - val_loss: 185.5504\n",
      "Epoch 406/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 157.1846 - val_loss: 185.3865\n",
      "Epoch 407/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 157.0582 - val_loss: 185.2287\n",
      "Epoch 408/500\n",
      "99/99 [==============================] - 0s 61us/step - loss: 156.9306 - val_loss: 185.0763\n",
      "Epoch 409/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 156.8021 - val_loss: 184.9288\n",
      "Epoch 410/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 156.6727 - val_loss: 184.7856\n",
      "Epoch 411/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 156.5426 - val_loss: 184.6463\n",
      "Epoch 412/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 156.4118 - val_loss: 184.5105\n",
      "Epoch 413/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 156.2804 - val_loss: 184.3778\n",
      "Epoch 414/500\n",
      "99/99 [==============================] - 0s 51us/step - loss: 156.1485 - val_loss: 184.2479\n",
      "Epoch 415/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 156.0161 - val_loss: 184.1204\n",
      "Epoch 416/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 155.8833 - val_loss: 183.9951\n",
      "Epoch 417/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 155.7501 - val_loss: 183.8718\n",
      "Epoch 418/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 155.6166 - val_loss: 183.7502\n",
      "Epoch 419/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 155.4828 - val_loss: 183.6302\n",
      "Epoch 420/500\n",
      "99/99 [==============================] - 0s 51us/step - loss: 155.3493 - val_loss: 183.5073\n",
      "Epoch 421/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 155.2190 - val_loss: 183.3820\n",
      "Epoch 422/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 155.0887 - val_loss: 183.2544\n",
      "Epoch 423/500\n",
      "99/99 [==============================] - 0s 51us/step - loss: 154.9584 - val_loss: 183.1246\n",
      "Epoch 424/500\n",
      "99/99 [==============================] - 0s 51us/step - loss: 154.8280 - val_loss: 182.9930\n",
      "Epoch 425/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 154.6976 - val_loss: 182.8594\n",
      "Epoch 426/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 154.5671 - val_loss: 182.7242\n",
      "Epoch 427/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 154.4365 - val_loss: 182.5874\n",
      "Epoch 428/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 154.3058 - val_loss: 182.4491\n",
      "Epoch 429/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 154.1750 - val_loss: 182.3094\n",
      "Epoch 430/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 154.0442 - val_loss: 182.1685\n",
      "Epoch 431/500\n",
      "99/99 [==============================] - 0s 50us/step - loss: 153.9132 - val_loss: 182.0263\n",
      "Epoch 432/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 153.7822 - val_loss: 181.8829\n",
      "Epoch 433/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 153.6510 - val_loss: 181.7385\n",
      "Epoch 434/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 153.5197 - val_loss: 181.5930\n",
      "Epoch 435/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 153.3883 - val_loss: 181.4466\n",
      "Epoch 436/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 153.2568 - val_loss: 181.2992\n",
      "Epoch 437/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 153.1252 - val_loss: 181.1509\n",
      "Epoch 438/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 152.9934 - val_loss: 181.0017\n",
      "Epoch 439/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 152.8616 - val_loss: 180.8517\n",
      "Epoch 440/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 152.7296 - val_loss: 180.7009\n",
      "Epoch 441/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 152.5974 - val_loss: 180.5493\n",
      "Epoch 442/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 152.4651 - val_loss: 180.3970\n",
      "Epoch 443/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 152.3327 - val_loss: 180.2439\n",
      "Epoch 444/500\n",
      "99/99 [==============================] - 0s 50us/step - loss: 152.2002 - val_loss: 180.0901\n",
      "Epoch 445/500\n",
      "99/99 [==============================] - 0s 50us/step - loss: 152.0675 - val_loss: 179.9355\n",
      "Epoch 446/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 151.9346 - val_loss: 179.7803\n",
      "Epoch 447/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 151.8017 - val_loss: 179.6245\n",
      "Epoch 448/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 151.6685 - val_loss: 179.4679\n",
      "Epoch 449/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 151.5352 - val_loss: 179.3107\n",
      "Epoch 450/500\n",
      "99/99 [==============================] - 0s 51us/step - loss: 151.4018 - val_loss: 179.1528\n",
      "Epoch 451/500\n",
      "99/99 [==============================] - 0s 51us/step - loss: 151.2682 - val_loss: 178.9942\n",
      "Epoch 452/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 151.1344 - val_loss: 178.8350\n",
      "Epoch 453/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 151.0005 - val_loss: 178.6752\n",
      "Epoch 454/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 150.8664 - val_loss: 178.5148\n",
      "Epoch 455/500\n",
      "99/99 [==============================] - 0s 50us/step - loss: 150.7322 - val_loss: 178.3537\n",
      "Epoch 456/500\n",
      "99/99 [==============================] - 0s 51us/step - loss: 150.5977 - val_loss: 178.1921\n",
      "Epoch 457/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 150.4632 - val_loss: 178.0297\n",
      "Epoch 458/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 150.3284 - val_loss: 177.8668\n",
      "Epoch 459/500\n",
      "99/99 [==============================] - 0s 51us/step - loss: 150.1935 - val_loss: 177.7032\n",
      "Epoch 460/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 150.0584 - val_loss: 177.5390\n",
      "Epoch 461/500\n",
      "99/99 [==============================] - 0s 41us/step - loss: 149.9231 - val_loss: 177.3742\n",
      "Epoch 462/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 149.7876 - val_loss: 177.2088\n",
      "Epoch 463/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 149.6520 - val_loss: 177.0428\n",
      "Epoch 464/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 149.5162 - val_loss: 176.8761\n",
      "Epoch 465/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 149.3802 - val_loss: 176.7088\n",
      "Epoch 466/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 149.2440 - val_loss: 176.5409\n",
      "Epoch 467/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 149.1076 - val_loss: 176.3724\n",
      "Epoch 468/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 148.9710 - val_loss: 176.2032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 469/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 148.8343 - val_loss: 176.0334\n",
      "Epoch 470/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 148.6973 - val_loss: 175.8630\n",
      "Epoch 471/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 148.5602 - val_loss: 175.6920\n",
      "Epoch 472/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 148.4237 - val_loss: 175.5249\n",
      "Epoch 473/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 148.2877 - val_loss: 175.3613\n",
      "Epoch 474/500\n",
      "99/99 [==============================] - 0s 51us/step - loss: 148.1513 - val_loss: 175.2009\n",
      "Epoch 475/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 148.0145 - val_loss: 175.0433\n",
      "Epoch 476/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 147.8774 - val_loss: 174.8882\n",
      "Epoch 477/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 147.7400 - val_loss: 174.7352\n",
      "Epoch 478/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 147.6023 - val_loss: 174.5842\n",
      "Epoch 479/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 147.4643 - val_loss: 174.4347\n",
      "Epoch 480/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 147.3262 - val_loss: 174.2868\n",
      "Epoch 481/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 147.1878 - val_loss: 174.1402\n",
      "Epoch 482/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 147.0504 - val_loss: 173.9899\n",
      "Epoch 483/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 146.9128 - val_loss: 173.8364\n",
      "Epoch 484/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 146.7749 - val_loss: 173.6797\n",
      "Epoch 485/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 146.6367 - val_loss: 173.5203\n",
      "Epoch 486/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 146.4982 - val_loss: 173.3582\n",
      "Epoch 487/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 146.3593 - val_loss: 173.1937\n",
      "Epoch 488/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 146.2202 - val_loss: 173.0269\n",
      "Epoch 489/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 146.0807 - val_loss: 172.8580\n",
      "Epoch 490/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 145.9419 - val_loss: 172.6920\n",
      "Epoch 491/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 145.8031 - val_loss: 172.5285\n",
      "Epoch 492/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 145.6640 - val_loss: 172.3671\n",
      "Epoch 493/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 145.5246 - val_loss: 172.2077\n",
      "Epoch 494/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 145.3851 - val_loss: 172.0499\n",
      "Epoch 495/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 145.2453 - val_loss: 171.8937\n",
      "Epoch 496/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 145.1053 - val_loss: 171.7387\n",
      "Epoch 497/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 144.9652 - val_loss: 171.5848\n",
      "Epoch 498/500\n",
      "99/99 [==============================] - 0s 40us/step - loss: 144.8249 - val_loss: 171.4318\n",
      "Epoch 499/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 144.6845 - val_loss: 171.2748\n",
      "Epoch 500/500\n",
      "99/99 [==============================] - 0s 30us/step - loss: 144.5444 - val_loss: 171.1140\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train, Y_train,\n",
    "          batch_size=128, epochs=500,\n",
    "          validation_data=(X_val, Y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Val'], loc='upper right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
